# Dissertation

Dynamic Difficulty adjustment aided by Reinforcement Learning in Strategy games.

# TODO List

- Set up tensor board and such for agent monitoring - 1 : Done by the 2nd Mar - Tensorboard is setup as part of the training, but stats recorder is to be fine tuned.
<!-- - Decide on what RL agent/SM agent data during training would be best for the DDA system - 2-4 : Done by the 2nd March - Likely will be player score, inventory, and the total number of score stored in inventory, and only from the RL Agent. this will be used to set a comparison for the decision tree to realise which RL Agent the player is performing most similarly to --> 
- Everything is ready to train the RL Agent. Expected training duration needed (maximum) - 30 hours, split across 3 weeks. : Start by the 3rd March. End by 23rd March latest
- Data gathering for DDA is done. To make it write to a csv file and such after training.
- DDA system should not take longer than 2-3 weeks to develop and implement, and final testing of the prototype and data collection scripts added by end of 2nd week of April, with end of April being the absolute limit if things go poorly. Goal is to allow 2-3 weeks in april and may for assignments, and cleaning up/finalising the earlier parts of the paper, and leaving 3 weeks for evaluation, conclusion and abstract.