# Dissertation

Dynamic Difficulty adjustment aided by Reinforcement Learning in Strategy games.

# TODO List

<!-- - Decide on what RL agent/SM agent data during training would be best for the DDA system - 2-4 : Done by the 2nd March - Likely will be player score, inventory, and the total number of score stored in inventory, and only from the RL Agent. this will be used to set a comparison for the decision tree to realise which RL Agent the player is performing most similarly to --> 
- Most bugs fixed, but small issue with ore finding and pathfinding to be checked out, since this doesnt happen outside of coroutines with the state machine. (Agent training is working and very minor progression was observer, so likely no reward changes will be needed once true final training begins and all bugs are ironed out)
- Everything is ready to train the RL Agent. Expected training duration needed (maximum) - 30 hours, split across 3 weeks. : Start by the 3rd March. End by 23rd March latest
- Data gathering for DDA is done. To make it write to a csv file and such after training.
- DDA system should not take longer than 2-3 weeks to develop and implement, and final testing of the prototype and data collection scripts added by end of 2nd week of April, with end of April being the absolute limit if things go poorly. Goal is to allow 2-3 weeks in april and may for assignments, and cleaning up/finalising the earlier parts of the paper, and leaving 3 weeks for evaluation, conclusion and abstract.